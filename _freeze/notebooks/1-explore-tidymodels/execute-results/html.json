{
  "hash": "aedefd6f586a877677f29edbb80eaec2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exploration using Tidymodels\"\nformat: html\n---\n\n# The Surfing for Science data base\n\nLoad the `tidymodels` library along with other useful ones:\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n✔ broom        1.0.8     ✔ recipes      1.3.0\n✔ dials        1.4.0     ✔ rsample      1.3.0\n✔ dplyr        1.1.4     ✔ tibble       3.2.1\n✔ ggplot2      3.5.2     ✔ tidyr        1.3.1\n✔ infer        1.0.8     ✔ tune         1.3.0\n✔ modeldata    1.4.0     ✔ workflows    1.2.0\n✔ parsnip      1.3.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.4     ✔ yardstick    1.3.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(readr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'readr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:yardstick':\n\n    spec\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:scales':\n\n    col_factor\n```\n\n\n:::\n:::\n\n\nLoad the full dataset from the Surging for Science project, also clean the variables names so they use `snake_case` and skip superfluous metadata. Character predictors are converter to type `factor` for compatibility with recipes.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics <- read_csv(\"data/surfingforscience_240325.csv\",\n                     col_types = cols(\n                       Particle_Num = col_skip(), \n                       Cruise_Name = col_skip(), Transect = col_skip(), \n                       Replicate = col_skip(), Sieve = col_skip(), \n                       Subsample = col_skip(), File_Name = col_skip(), \n                       Modified = col_skip(), ImageType = col_skip())) |> \njanitor::clean_names() |> \nmutate_if(is.character, as.factor)\n```\n:::\n\n\nThe aim of this notebook is to evaluate performance of different models following the [tidymodels](https://www.tidymodels.org/) workflow. To evaluate performance we need plastics that have been evaluated manually so we can compare the trained human observer with the AI. A *good* model is the one that gets us very similar results to the trained human.\n\nSubset the data to get all plastics evaluated by a human observer.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_manual <- plastics |> filter(rf_use == FALSE)\n```\n:::\n\n\nOverall, the model currently in use had a 58.9% success rate.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_manual |> \n  count(rf_success = as.character(group) == as.character(rf_group)) |> \n  mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 3\n  rf_success     n  prop\n  <lgl>      <int> <dbl>\n1 FALSE      23656 0.411\n2 TRUE       33857 0.589\n```\n\n\n:::\n:::\n\n\nRemove all variables related to the current model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_manual <- plastics_manual |> \n  select(-starts_with(\"prob\"), -starts_with(\"rf\"))\n```\n:::\n\n\nBefore fitting new models, data splitting is done to avoid training and evaluating the model with the same set of data. If so was done, the performance results would be overly optimistic due to overfitting. The training dataset is intended to have plastics of all types in similar proportion, this is achieved by setting the argument `strata = group`.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_split <- plastics_manual |> initial_split(prop = 3/4, strata = group)\n```\n:::\n\n\nAfter checking the relative group composition of our training set we observe that some groups are very rare: `Fibre.bundle`, `Paint.chip` and `NA.Other`\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\ntrain_plastics <- training(plastics_split)\ntest_plastics <- testing(plastics_split)\n\ntrain_plastics |> count(group) |> mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 3\n   group                  n      prop\n   <fct>              <int>     <dbl>\n 1 Artificial.turf      847 0.0196   \n 2 Fibre                107 0.00248  \n 3 Fibre.bundle           7 0.000162 \n 4 Filament             845 0.0196   \n 5 Film.Sheet         11088 0.257    \n 6 Foam                3602 0.0835   \n 7 Fragment           26176 0.607    \n 8 NA.Other              37 0.000858 \n 9 Paint.chip             1 0.0000232\n10 Pellet               142 0.00329  \n11 Spherule.Microbead   282 0.00654  \n```\n\n\n:::\n:::\n\n\n# Preprocessin using recipes\n\nLet's initialize a simple recipe for our first model\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_recipe <- train_plastics |> recipe(group ~ .) |> \n  step_dummy(all_nominal_predictors()) |> \n  step_zv(all_predictors())\n```\n:::\n\n\nNext, define a random forest model of 1000 trees using the `ranger` engine.\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrf_mod <- \n  rand_forest(trees = 100) |> \n  set_engine(\"ranger\") |> \n  set_mode(\"classification\")\n```\n:::\n\n\nCreate a modelling workflow that combines the model and the recipe\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nplastics_wflow <- workflow() |> add_model(rf_mod) |> add_recipe(plastics_recipe)\n```\n:::\n\n\nFit the workflow to the training data\n\n::: {.callout-warning}\nHeavy computation ahead\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrf_fit <- plastics_wflow |> fit(data = train_plastics)\n```\n:::\n\nLet's see how it went\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrf_fit |> extract_fit_parsnip()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nparsnip model object\n\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~100,      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  100 \nSample size:                      43134 \nNumber of independent variables:  152 \nMtry:                             12 \nTarget node size:                 10 \nVariable importance mode:         none \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.2001236 \n```\n\n\n:::\n:::\n\n\n# Evaluating performance using resamples\n\nLets create a 10 fold cross validation resample\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(567)\nfolds <- train_plastics |> vfold_cv(v = 4)\n```\n:::\n\n\nNow fit the workflow to the resamples\n\n::: {.callout-warning}\nHeavy computation ahead\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nset.seed(311)\nrf_fit_rs <- plastics_wflow |> fit_resamples(folds)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n→ A | warning: Dropped unused factor level(s) in dependent variable: Paint.chip.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThere were issues with some computations   A: x1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n→ B | error:   Failed to compute `roc_auc()`.\n               Caused by error:\n               ! Can't select columns that don't exist.\n               ✖ Column `.pred_Paint.chip` doesn't exist.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1   B: x1\n→ C | warning: ✖ No observations were detected in `truth` for level: Paint.chip.\n               ℹ Computation will proceed by ignoring those levels.\nThere were issues with some computations   A: x1   B: x1\nThere were issues with some computations   A: x1   B: x1   C: x1\nThere were issues with some computations   A: x1   B: x1   C: x2\nThere were issues with some computations   A: x1   B: x1   C: x3\nThere were issues with some computations   A: x1   B: x1   C: x3\n```\n\n\n:::\n:::\n\nFinally, collect the metrics and see how it did\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nrf_fit_rs |> collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 6\n  .metric     .estimator  mean     n  std_err .config             \n  <chr>       <chr>      <dbl> <int>    <dbl> <chr>               \n1 accuracy    multiclass 0.762     3 0.00227  Preprocessor1_Model1\n2 brier_class multiclass 0.172     3 0.000966 Preprocessor1_Model1\n3 roc_auc     hand_till  0.863     3 0.00977  Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}